{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import lyricsgenius\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"./data/raw/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 116\n",
    "clientID = os.getenv(\"clientID\")\n",
    "clientAccessToken = os.getenv(\"clientAccessToken\")\n",
    "clientSecret = os.getenv(\"clientSecret\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchAndSave(artist, genius):\n",
    "    print(\"search for \" + artist)\n",
    "    artist = genius.search_artist(artist, max_songs=500, per_page= 50, sort=\"popularity\", get_full_info= False)\n",
    "    print(\"saving lyrics\")\n",
    "    artist.save_lyrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"../../topRappers.txt\", \"r\") as fp:\n",
    "    genius = lyricsgenius.Genius(client_access_token = clientAccessToken, verbose=False, timeout = 15)\n",
    "    genius.excluded_terms = [\"(Remix)\", \"(Live)\"]\n",
    "    count = 0\n",
    "    for i, artist in enumerate(fp):\n",
    "        # print(artist)\n",
    "        # print (i)\n",
    "        if i >=  offset :\n",
    "            try:\n",
    "                fetchAndSave(artist, genius)\n",
    "            except TimeoutError:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "files = os.listdir(\"./data/raw/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for filename in files:\n",
    "# temp = \"\"\n",
    "# filename = \"Lyrics_Dax.json\"\n",
    "    with open(f'./data/raw/{filename}') as f:\n",
    "        data = json.load(f)\n",
    "        song_obj = {}\n",
    "        artist = data[\"name\"]\n",
    "        song_obj[artist] = []\n",
    "        for song in data['songs']:\n",
    "            lyrics = song['lyrics']\n",
    "            if \"Lyrics for this song have yet to be released\" in lyrics:\n",
    "                continue\n",
    "            # lyrics.decode(\"utf-8\")\n",
    "            # print(lyrics)\n",
    "            # temp = lyrics\n",
    "            song_obj[artist].append(song['lyrics'])\n",
    "        with open(f'./data/cleaned/{artist}.json', 'w', encoding='utf-8') as outfile:\n",
    "            json.dump(song_obj, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2TokenizerFast\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "tokenizer.tokenize(lyrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}